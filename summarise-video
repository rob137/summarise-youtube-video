#!/usr/bin/env python3
"""
YouTube Transcript Summarizer
A command-line tool that extracts YouTube video transcripts, 
cleans them up with AI, and generates structured summaries.
"""

import sys
import os
import re
import json

import subprocess
import tempfile
import time
import threading
from urllib.parse import urlparse, parse_qs
from typing import List, Dict, Optional, Tuple
import requests
from datetime import datetime

class YouTubeTranscriptSummarizer:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        # Validate configuration
        self.gemini_base_url = "https://generativelanguage.googleapis.com/v1beta/models"
        assert isinstance(self.gemini_base_url, str)
        assert self.gemini_base_url.startswith("https://"), "API base URL must use HTTPS"
        
        self.cleaning_model = "gemini-2.0-flash-exp"
        assert isinstance(self.cleaning_model, str)
        assert len(self.cleaning_model) > 0, "Cleaning model name cannot be empty"
        
        self.summary_model = "gemini-2.5-pro"
        assert isinstance(self.summary_model, str)
        assert len(self.summary_model) > 0, "Summary model name cannot be empty"
        
        self.max_retries = 3
        assert isinstance(self.max_retries, int)
        assert self.max_retries > 0, "Max retries must be positive"
        
        self.base_delay = 1
        assert isinstance(self.base_delay, int)
        assert self.base_delay > 0, "Base delay must be positive"
        
        self.api_timeout = 300  # seconds
        assert isinstance(self.api_timeout, int)
        assert self.api_timeout > 0, "API timeout must be positive"
        
        self.start_time = None
        self.progress_timer = None
        self.stop_progress = False
        
        # Cost tracking (USD per 1M tokens)
        self.model_costs = {
            "gemini-2.5-pro": {"input": 1.25, "output": 10.00}
        }
        assert isinstance(self.model_costs, dict), "Model costs must be a dictionary"
        for model, costs in self.model_costs.items():
            assert isinstance(model, str), f"Model name must be string, got {type(model)}"
            assert isinstance(costs, dict), f"Costs for {model} must be dict"
            assert "input" in costs and "output" in costs, f"Model {model} missing input/output costs"
            assert costs["input"] > 0 and costs["output"] > 0, f"Model {model} costs must be positive"
        
        self.usage_stats = {
            "cleaning_input_tokens": 0,
            "cleaning_output_tokens": 0,
            "summary_input_tokens": 0,
            "summary_output_tokens": 0,
            "total_cost": 0.0
        }
        assert isinstance(self.usage_stats, dict), "Usage stats must be a dictionary"
        for key, value in self.usage_stats.items():
            assert isinstance(key, str), f"Usage stat key must be string, got {type(key)}"
            assert isinstance(value, (int, float)), f"Usage stat {key} must be numeric, got {type(value)}"
            assert value >= 0, f"Usage stat {key} must be non-negative, got {value}"
    
    def _start_progress_timer(self, operation_name: str):
        """Start a progress timer that shows elapsed time."""
        assert isinstance(operation_name, str), f"Operation name must be string, got {type(operation_name)}"
        assert len(operation_name.strip()) > 0, "Operation name cannot be empty"
        
        self.start_time = time.time()
        self.stop_progress = False
        
        def show_progress():
            while not self.stop_progress:
                assert self.start_time is not None, "Start time should be set"
                elapsed = time.time() - self.start_time
                assert elapsed >= 0, f"Elapsed time cannot be negative: {elapsed}"
                minutes = int(elapsed // 60)
                seconds = int(elapsed % 60)
                # Clear the line completely before writing new content
                print(f"\r{' ' * 80}\r[{minutes:02d}:{seconds:02d}] {operation_name}...", end="", flush=True)
                time.sleep(1)
        
        self.progress_timer = threading.Thread(target=show_progress, daemon=True)
        self.progress_timer.start()
    
    def _stop_progress_timer(self):
        """Stop the progress timer."""
        if self.progress_timer:
            self.stop_progress = True
            elapsed = time.time() - self.start_time if self.start_time else 0
            minutes = int(elapsed // 60)
            seconds = int(elapsed % 60)
            # Clear the line completely and show completion
            print(f"\r{' ' * 80}\r[{minutes:02d}:{seconds:02d}] âœ“ Completed")
        
    def _make_api_request_with_retry(self, url: str, payload: dict, headers: dict, operation_name: str) -> requests.Response:
        """Make API request with exponential backoff retry logic."""
        assert isinstance(url, str), f"URL must be string, got {type(url)}"
        assert url.startswith("https://"), f"URL must use HTTPS: {url}"
        assert isinstance(payload, dict), f"Payload must be dict, got {type(payload)}"
        assert isinstance(headers, dict), f"Headers must be dict, got {type(headers)}"
        assert isinstance(operation_name, str), f"Operation name must be string, got {type(operation_name)}"
        assert len(operation_name.strip()) > 0, "Operation name cannot be empty"
        
        print(f"Starting {operation_name} (timeout: {self.api_timeout}s)...")
        for attempt in range(self.max_retries):
            try:
                response = requests.post(url, json=payload, headers=headers, timeout=self.api_timeout)
                if response.status_code == 200:
                    return response
                elif response.status_code == 429:  # Rate limit
                    if attempt < self.max_retries - 1:
                        delay = self.base_delay * (2 ** attempt)
                        print(f"Rate limit hit for {operation_name}, retrying in {delay}s...")
                        time.sleep(delay)
                        continue
                else:
                    print(f"API error for {operation_name}: HTTP {response.status_code}")
                    if response.text:
                        print(f"Response: {response.text}")
                    response.raise_for_status()
            except requests.exceptions.Timeout as e:
                elapsed = time.time() - self.start_time if self.start_time else 0
                minutes = int(elapsed // 60)
                seconds = int(elapsed % 60)
                if attempt < self.max_retries - 1:
                    delay = self.base_delay * (2 ** attempt)
                    print(f"\nTimeout after {minutes:02d}:{seconds:02d} for {operation_name} (attempt {attempt + 1}/{self.max_retries}), retrying in {delay}s...")
                    time.sleep(delay)
                    continue
                else:
                    print(f"\nFinal timeout after {minutes:02d}:{seconds:02d} for {operation_name} - all {self.max_retries} attempts failed")
                    raise TimeoutError(f"{operation_name} timed out after {minutes:02d}:{seconds:02d} ({self.max_retries} attempts)")
            except requests.exceptions.ConnectionError as e:
                if attempt < self.max_retries - 1:
                    delay = self.base_delay * (2 ** attempt)
                    print(f"Connection error for {operation_name} (attempt {attempt + 1}/{self.max_retries}), retrying in {delay}s...")
                    time.sleep(delay)
                    continue
                else:
                    raise e
        
        # If we get here, all retries failed
        raise Exception(f"All {self.max_retries} attempts failed for {operation_name}")
        
    def extract_video_id(self, url: str) -> Optional[str]:
        """Extract video ID from various YouTube URL formats."""
        assert isinstance(url, str), f"URL must be string, got {type(url)}"
        assert len(url.strip()) > 0, "URL cannot be empty"
        
        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([a-zA-Z0-9_-]+)',
            r'youtube\.com/watch\?.*v=([a-zA-Z0-9_-]+)',
        ]
        
        for pattern in patterns:
            assert isinstance(pattern, str), f"Pattern must be string, got {type(pattern)}"
            match = re.search(pattern, url)
            if match:
                video_id = match.group(1)
                assert isinstance(video_id, str), f"Video ID must be string, got {type(video_id)}"
                assert len(video_id) > 0, "Video ID cannot be empty"
                assert re.match(r'^[a-zA-Z0-9_-]+$', video_id), f"Invalid video ID format: {video_id}"
                return video_id
        return None
    
    def get_transcript(self, video_url: str) -> List[Dict]:
        """Extract transcript using yt-dlp."""
        assert isinstance(video_url, str), f"Video URL must be string, got {type(video_url)}"
        assert len(video_url.strip()) > 0, "Video URL cannot be empty"
        
        try:
            video_id = self.extract_video_id(video_url)
            if not video_id:
                raise ValueError("Invalid YouTube URL")
            
            assert isinstance(video_id, str), f"Video ID must be string, got {type(video_id)}"
            assert len(video_id) > 0, "Video ID cannot be empty"
            
            # Create temp file for transcript
            with tempfile.NamedTemporaryFile(mode='w', suffix='.vtt', delete=False) as temp_file:
                temp_path = temp_file.name
            
            assert isinstance(temp_path, str), f"Temp path must be string, got {type(temp_path)}"
            assert os.path.exists(os.path.dirname(temp_path)), f"Temp directory doesn't exist: {os.path.dirname(temp_path)}"
            
            # Use yt-dlp to extract transcript
            cmd = [
                'yt-dlp', 
                '--write-auto-subs', 
                '--write-subs',
                '--sub-langs', 'en',
                '--sub-format', 'vtt',
                '--skip-download',
                '--output', temp_path.replace('.vtt', ''),
                video_url
            ]
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            except subprocess.TimeoutExpired:
                raise TimeoutError("Transcript extraction timed out after 30 seconds")
            
            if result.returncode != 0:
                # Fallback: try with different subtitle options
                cmd = [
                    'yt-dlp', 
                    '--write-auto-subs',
                    '--sub-langs', 'en',
                    '--sub-format', 'json3',
                    '--skip-download',
                    '--output', temp_path.replace('.vtt', ''),
                    video_url
                ]
                try:
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                except subprocess.TimeoutExpired:
                    raise TimeoutError("Transcript extraction (fallback) timed out after 30 seconds")
            
            # Find the generated subtitle files
            transcript_files = []
            base_path = temp_path.replace('.vtt', '')
            
            for ext in ['.en.vtt', '.en.json3']:
                potential_file = base_path + ext
                if os.path.exists(potential_file):
                    transcript_files.append(potential_file)
            
            if not transcript_files:
                raise FileNotFoundError("No transcript files found")
            
            # Parse the transcript
            transcript = self.parse_transcript_file(transcript_files[0])
            assert isinstance(transcript, list), f"Transcript must be list, got {type(transcript)}"
            
            # Quick logging to show timestamp data
            if transcript:
                print(f"DEBUG: First few transcript entries with timestamps:")
                for i, entry in enumerate(transcript[:3]):
                    if 'start' in entry:
                        minutes = int(entry['start'] // 60)
                        seconds = int(entry['start'] % 60)
                        print(f"  {minutes:02d}:{seconds:02d} - {entry['text'][:50]}...")
                    if i >= 2:
                        break
            
            # Cleanup temp files
            for file in transcript_files:
                try:
                    os.unlink(file)
                except:
                    pass
            try:
                os.unlink(temp_path)
            except:
                pass
            
            # Validate transcript structure
            for i, entry in enumerate(transcript):
                assert isinstance(entry, dict), f"Transcript entry {i} must be dict, got {type(entry)}"
                assert 'start' in entry, f"Transcript entry {i} missing 'start' field"
                assert 'text' in entry, f"Transcript entry {i} missing 'text' field"
                assert isinstance(entry['start'], (int, float)), f"Transcript entry {i} 'start' must be numeric, got {type(entry['start'])}"
                assert entry['start'] >= 0, f"Transcript entry {i} 'start' must be non-negative, got {entry['start']}"
                assert isinstance(entry['text'], str), f"Transcript entry {i} 'text' must be string, got {type(entry['text'])}"
                
            return transcript
            
        except TimeoutError as e:
            raise RuntimeError(f"Transcript extraction failed: {str(e)}")
        except Exception as e:
            raise RuntimeError(f"Failed to extract transcript: {str(e)}")
    
    def parse_transcript_file(self, file_path: str) -> List[Dict]:
        """Parse transcript file (VTT or JSON3 format)."""
        assert isinstance(file_path, str), f"File path must be string, got {type(file_path)}"
        assert len(file_path.strip()) > 0, "File path cannot be empty"
        assert os.path.exists(file_path), f"Transcript file doesn't exist: {file_path}"
        
        transcript = []
        
        if file_path.endswith('.vtt'):
            transcript = self.parse_vtt_file(file_path)
        elif file_path.endswith('.json3'):
            transcript = self.parse_json3_file(file_path)
        else:
            raise ValueError(f"Unsupported transcript file format: {file_path}")
        
        assert isinstance(transcript, list), f"Parsed transcript must be list, got {type(transcript)}"
        return transcript
    
    def parse_vtt_file(self, file_path: str) -> List[Dict]:
        """Parse VTT subtitle file."""
        transcript = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Split by double newlines to get individual subtitle blocks
        blocks = re.split(r'\n\n+', content)
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 2:
                # Look for timestamp line
                timestamp_pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3})'
                timestamp_match = None
                text_lines = []
                
                for line in lines:
                    match = re.search(timestamp_pattern, line)
                    if match:
                        timestamp_match = match
                    elif line.strip() and not line.startswith('WEBVTT') and not re.match(r'^\d+$', line.strip()):
                        # Remove HTML tags and clean text
                        clean_text = re.sub(r'<[^>]+>', '', line.strip())
                        if clean_text:
                            text_lines.append(clean_text)
                
                if timestamp_match and text_lines:
                    start_time = self.timestamp_to_seconds(timestamp_match.group(1))
                    transcript.append({
                        'start': start_time,
                        'text': ' '.join(text_lines)
                    })
        
        return transcript
    
    def parse_json3_file(self, file_path: str) -> List[Dict]:
        """Parse JSON3 subtitle file."""
        transcript = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'events' in data:
            for event in data['events']:
                if 'segs' in event and event.get('tStartMs') is not None:
                    text_parts = []
                    for seg in event['segs']:
                        if 'utf8' in seg:
                            text_parts.append(seg['utf8'])
                    
                    if text_parts:
                        start_seconds = event['tStartMs'] / 1000.0
                        transcript.append({
                            'start': start_seconds,
                            'text': ''.join(text_parts).strip()
                        })
        
        return transcript
    
    def timestamp_to_seconds(self, timestamp: str) -> float:
        """Convert timestamp string to seconds."""
        assert isinstance(timestamp, str), f"Timestamp must be string, got {type(timestamp)}"
        assert len(timestamp.strip()) > 0, "Timestamp cannot be empty"
        
        parts = timestamp.split(':')
        assert len(parts) == 3, f"Timestamp must have format HH:MM:SS.mmm, got: {timestamp}"
        
        hours = int(parts[0])
        minutes = int(parts[1])
        seconds_parts = parts[2].split('.')
        seconds = int(seconds_parts[0])
        milliseconds = int(seconds_parts[1]) if len(seconds_parts) > 1 else 0
        
        assert 0 <= hours <= 23, f"Hours must be 0-23, got {hours}"
        assert 0 <= minutes <= 59, f"Minutes must be 0-59, got {minutes}"
        assert 0 <= seconds <= 59, f"Seconds must be 0-59, got {seconds}"
        assert 0 <= milliseconds <= 999, f"Milliseconds must be 0-999, got {milliseconds}"
        
        total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000.0
        assert total_seconds >= 0, f"Total seconds cannot be negative: {total_seconds}"
        return total_seconds
        
    def extract_transcript_text(self, transcript: List[Dict]) -> str:
        """Extract just the text from transcript entries."""
        assert isinstance(transcript, list), f"Transcript must be list, got {type(transcript)}"
        
        text_parts = []
        for i, entry in enumerate(transcript):
            assert isinstance(entry, dict), f"Transcript entry {i} must be dict, got {type(entry)}"
            assert 'text' in entry, f"Transcript entry {i} missing 'text' field"
            assert isinstance(entry['text'], str), f"Transcript entry {i} 'text' must be string, got {type(entry['text'])}"
            text_parts.append(entry['text'])
        
        return " ".join(text_parts)

     

    
    def clean_transcript(self, transcript_text: str, video_title: str = "") -> str:
        """Clean the full transcript using Gemini API."""
        if not self.api_key:
            print("Error: GEMINI_API_KEY is required for transcript cleaning")
            sys.exit(1)
        
        try:
            # Use the provided transcript text directly
            text = transcript_text
            
            title_context = f"\n\nVideo title: {video_title}" if video_title else ""
            
            prompt = f"""Please clean up this YouTube transcript excerpt. Remove filler words, fix grammar, and improve readability while preserving the original meaning and important timestamps. Keep the content natural and flowing.

If you notice any misspelled names or terms, please gently correct them using common sense (especially proper nouns that might be auto-transcribed incorrectly).{title_context}

{text}

Return only the cleaned text without any additional formatting or commentary."""

            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "maxOutputTokens": 60000
                }
            }
            
            headers = {"Content-Type": "application/json"}
            response = self._make_api_request_with_retry(
                f"{self.gemini_base_url}/{self.cleaning_model}:generateContent?key={self.api_key}",
                payload,
                headers,
                "transcript cleaning"
            )
            
            if response.status_code == 200:
                result = response.json()
                
                if 'candidates' in result and result['candidates']:
                    candidate = result['candidates'][0]
                    
                    # Check for MAX_TOKENS finish reason
                    if candidate.get('finishReason') == 'MAX_TOKENS':
                        print(f"Warning: Response was truncated due to MAX_TOKENS limit. Consider reducing chunk size.")
                        if 'content' in candidate and 'parts' in candidate['content'] and candidate['content']['parts']:
                            # Still return the truncated response - it's better than nothing
                            return candidate['content']['parts'][0]['text'].strip()
                        else:
                            print(f"Error: MAX_TOKENS response has no usable content: {candidate}")
                            return ""
                    
                    if 'content' in candidate and 'parts' in candidate['content']:
                        # Track token usage for cost calculation
                        if 'usageMetadata' in result:
                            input_tokens = result['usageMetadata'].get('promptTokenCount', 0)
                            output_tokens = result['usageMetadata'].get('candidatesTokenCount', 0)
                            self.usage_stats['cleaning_input_tokens'] += input_tokens
                            self.usage_stats['cleaning_output_tokens'] += output_tokens
                            self._update_cost('cleaning', input_tokens, output_tokens)
                        
                        return candidate['content']['parts'][0]['text'].strip()
                    else:
                        print(f"Error: Missing 'content' or 'parts' in candidate: {candidate}")
                else:
                    print(f"Error: No candidates found in API response: {result}")
            else:
                print(f"Error: API returned HTTP {response.status_code}")
                print(f"Response body: {response.text}")
            
            print("Error: Failed to get valid response from Gemini API for transcript cleaning")
            sys.exit(1)
            
        except Exception as e:
            print(f"Error: Transcript cleaning failed - {str(e)}")
            print(f"Exception type: {type(e).__name__}")
            if hasattr(e, 'response') and e.response:
                print(f"HTTP Status: {e.response.status_code}")
                print(f"Response headers: {dict(e.response.headers)}")
                print(f"Response body: {e.response.text}")
            import traceback
            print(f"Full traceback:\n{traceback.format_exc()}")
            sys.exit(1)
    
    def generate_all_summaries(self, clean_transcript: str, video_title: str = "") -> Dict[str, str]:
        """Generate all summary levels using a single prompt."""
        if not self.api_key:
            print("Error: GEMINI_API_KEY is required for summary generation")
            sys.exit(1)
        
        try:
            title_context = f"\n\nVideo title: {video_title}" if video_title else ""
            
            prompt = f"""Please summarize the following transcript at three levels of detail:

1. BRIEF (1 sentence): The absolute key takeaway in one sentence
2. MEDIUM (1 paragraph): Main points and key insights in paragraph form  
3. DETAILED: Comprehensive summary with all major points, insights, and important details organized clearly

Please ensure names and terms are spelled correctly, using the video title as context if helpful.{title_context}

Transcript:
{clean_transcript}

Please format your response exactly as:
BRIEF: [one sentence summary]

MEDIUM: [one paragraph summary]

DETAILED: [detailed summary with clear organization]"""

            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.2,
                    "maxOutputTokens": 3072
                }
            }
            
            headers = {"Content-Type": "application/json"}
            response = self._make_api_request_with_retry(
                f"{self.gemini_base_url}/{self.summary_model}:generateContent?key={self.api_key}",
                payload,
                headers,
                "summary generation"
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and result['candidates']:
                    # Track token usage for cost calculation
                    if 'usageMetadata' in result:
                        input_tokens = result['usageMetadata'].get('promptTokenCount', 0)
                        output_tokens = result['usageMetadata'].get('candidatesTokenCount', 0)
                        self.usage_stats['summary_input_tokens'] += input_tokens
                        self.usage_stats['summary_output_tokens'] += output_tokens
                        self._update_cost('summary', input_tokens, output_tokens)
                    
                    content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    return self.parse_multi_level_summary(content)
            
            print("Error: Failed to get valid response from Gemini API for summary generation")
            print("API returned a response but no valid content was found")
            sys.exit(1)
            
        except Exception as e:
            print(f"Error: Summary generation failed - {str(e)}")
            if hasattr(e, 'response') and e.response:
                print(f"HTTP Status: {e.response.status_code}")
                print(f"Response body: {e.response.text}")
            sys.exit(1)
    
    def parse_multi_level_summary(self, content: str) -> Dict[str, str]:
        """Parse the multi-level summary response."""
        summaries = {"brief": "", "medium": "", "detailed": ""}
        
        # Split content by the section headers
        sections = content.split('\n')
        current_section = None
        current_content = []
        
        for line in sections:
            line = line.strip()
            if line.startswith('BRIEF:'):
                if current_section and current_content:
                    summaries[current_section] = '\n'.join(current_content).strip()
                current_section = 'brief'
                current_content = [line.replace('BRIEF:', '').strip()]
            elif line.startswith('MEDIUM:'):
                if current_section and current_content:
                    summaries[current_section] = '\n'.join(current_content).strip()
                current_section = 'medium'
                current_content = [line.replace('MEDIUM:', '').strip()]
            elif line.startswith('DETAILED:'):
                if current_section and current_content:
                    summaries[current_section] = '\n'.join(current_content).strip()
                current_section = 'detailed'
                current_content = [line.replace('DETAILED:', '').strip()]
            elif current_section and line:
                current_content.append(line)
        
        # Don't forget the last section
        if current_section and current_content:
            summaries[current_section] = '\n'.join(current_content).strip()
        
        # Fallback if parsing fails
        if not any(summaries.values()):
            summaries["brief"] = content[:200] + "..." if len(content) > 200 else content
            summaries["medium"] = content
            summaries["detailed"] = content
        
        return summaries
    
    def get_video_title(self, video_url: str) -> str:
        """Extract video title using yt-dlp."""
        try:
            cmd = ['yt-dlp', '--get-title', video_url]
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            except subprocess.TimeoutExpired:
                print("Video title extraction timed out after 10 seconds")
                return "Unknown-Title"
            if result.returncode == 0:
                title = result.stdout.strip()
                # Clean title for filename
                title = re.sub(r'[^\w\s-]', '', title)
                title = re.sub(r'[-\s]+', '-', title)
                return title[:80]  # Limit length
            return "Unknown-Title"
        except:
            return "Unknown-Title"



    def _update_cost(self, operation: str, input_tokens: int, output_tokens: int):
        """Update cost tracking based on token usage."""
        model = self.cleaning_model if operation == 'cleaning' else self.summary_model
        if model in self.model_costs:
            input_cost = (input_tokens / 1_000_000) * self.model_costs[model]["input"]
            output_cost = (output_tokens / 1_000_000) * self.model_costs[model]["output"]
            self.usage_stats['total_cost'] += input_cost + output_cost

    def get_cost_summary(self) -> str:
        """Generate a cost summary string."""
        if not self.api_key:
            return "Cost tracking unavailable (no API key provided)"
        
        total_input = self.usage_stats['cleaning_input_tokens'] + self.usage_stats['summary_input_tokens']
        total_output = self.usage_stats['cleaning_output_tokens'] + self.usage_stats['summary_output_tokens']
        
        return f"""*Cost Summary:*
- Cleaning: {self.usage_stats['cleaning_input_tokens']:,} input + {self.usage_stats['cleaning_output_tokens']:,} output tokens
- Summary: {self.usage_stats['summary_input_tokens']:,} input + {self.usage_stats['summary_output_tokens']:,} output tokens
- Total: {total_input:,} input + {total_output:,} output tokens
- Estimated cost: ${self.usage_stats['total_cost']:.4f} USD"""

    def format_transcript_with_timestamps(self, transcript: List[Dict], clean_transcript: str, video_url: str, interval: int = 180) -> str:
        """Add hyperlinked timestamp markers to clean transcript every interval seconds."""
        if not transcript:
            return clean_transcript
        
        # Split clean transcript into words to match with original transcript
        clean_words = clean_transcript.split()
        transcript_words = []
        word_timestamps = []
        
        # Extract words and their approximate timestamps from original transcript
        for entry in transcript:
            entry_words = entry['text'].split()
            for word in entry_words:
                transcript_words.append(word)
                word_timestamps.append(entry['start'])
        
        # Build output with timestamp markers
        result = []
        last_marker_time = 0
        
        for i, clean_word in enumerate(clean_words):
            # Find approximate timestamp for this word position
            word_index = min(i, len(word_timestamps) - 1) if word_timestamps else 0
            current_time = word_timestamps[word_index] if word_timestamps else 0
            
            # Insert timestamp marker if we've crossed the interval
            if current_time >= last_marker_time + interval:
                marker_time = int(current_time)
                minutes = marker_time // 60
                seconds = marker_time % 60
                
                # Create hyperlinked timestamp
                timestamp_url = f"{video_url}&t={marker_time}s"
                result.append(f"\n\n**[{minutes:02d}:{seconds:02d}]({timestamp_url})**\n")
                last_marker_time = marker_time
            
            result.append(clean_word)
        
        return ' '.join(result)

    def format_output(self, video_url: str, clean_transcript: str, summaries: Dict[str, str], transcript: List[Dict] = None) -> str:
        """Format the final output in org mode format."""
        title = self.get_video_title(video_url)
        timestamp = datetime.now().strftime("%Y-%m-%d")
        
        # Add timestamp markers to transcript if original transcript data is available
        formatted_transcript = clean_transcript
        if transcript:
            formatted_transcript = self.format_transcript_with_timestamps(transcript, clean_transcript, video_url)
        
        output = f"""* {title.replace('-', ' ')}

*Date:* {timestamp}
*Source:* {video_url}

** Brief Summary
{summaries['brief']}

** Medium Summary
{summaries['medium']}

** Detailed Summary
{summaries['detailed']}

** Full Transcript
{formatted_transcript}

** Cost Information
{self.get_cost_summary()}
"""
        
        return output


    
    def process_video(self, video_url: str) -> str:
        """Main processing function."""
        try:
            self._start_progress_timer("Extracting transcript")
            transcript = self.get_transcript(video_url)
            self._stop_progress_timer()
            
            if not transcript:
                raise ValueError("No transcript found for this video")
            
            print(f"Found {len(transcript)} transcript segments")
            
            # Get video title for context
            self._start_progress_timer("Getting video title")
            video_title = self.get_video_title(video_url)
            self._stop_progress_timer()
            
            # Extract transcript text
            transcript_text = self.extract_transcript_text(transcript)
            
            # Clean the entire transcript at once
            self._start_progress_timer("Cleaning transcript")
            clean_transcript = self.clean_transcript(transcript_text, video_title)
            self._stop_progress_timer()
            
            # Generate summaries
            self._start_progress_timer("Generating summaries")
            summaries = self.generate_all_summaries(clean_transcript, video_title)
            self._stop_progress_timer()
            
            # Format output
            formatted_output = self.format_output(video_url, clean_transcript, summaries, transcript)
            
            # Print cost summary to console
            print(f"\n{self.get_cost_summary()}")
            
            # Generate default filename in ~/transcripts directory
            transcripts_dir = os.path.expanduser("~/transcripts")
            os.makedirs(transcripts_dir, exist_ok=True)
            
            title = self.get_video_title(video_url)
            default_filename = os.path.join(transcripts_dir, f"youtube-transcript-{title}.org")
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(formatted_output)
            print(f"Output saved to: {default_filename}")
            
            return formatted_output
            
        except Exception as e:
            error_msg = f"Error processing video: {str(e)}"
            print(error_msg)
            return error_msg

def main():
    assert len(sys.argv) >= 1, "sys.argv should always have at least the script name"
    
    if len(sys.argv) != 2:
        print("Usage: ./summarise-video <youtube_url>")
        sys.exit(1)
    
    video_url = sys.argv[1]
    assert isinstance(video_url, str), f"Video URL must be string, got {type(video_url)}"
    assert len(video_url.strip()) > 0, "Video URL cannot be empty"
    
    # Basic YouTube URL validation
    assert any(domain in video_url.lower() for domain in ['youtube.com', 'youtu.be']), f"Not a YouTube URL: {video_url}"
    
    # Check for yt-dlp
    try:
        subprocess.run(['yt-dlp', '--version'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("Error: yt-dlp is required but not found. Please install it:")
        print("pip install yt-dlp")
        sys.exit(1)
    
    # Initialize summarizer
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("Warning: No Gemini API key provided. AI features will be disabled.")
        print("Set GEMINI_API_KEY environment variable")
    
    summarizer = YouTubeTranscriptSummarizer(api_key)
    assert isinstance(summarizer, YouTubeTranscriptSummarizer), "Failed to create summarizer instance"
    
    try:
        result = summarizer.process_video(video_url)
        print("\nProcessing completed successfully!")
        
        # Print summary to terminal with visual formatting
        print("\n" + "="*80)
        print("ðŸ“‹ SUMMARY")
        print("="*80)
        
        # Extract summaries from the result
        lines = result.split('\n')
        in_brief = False
        in_medium = False
        in_detailed = False
        brief_content = []
        medium_content = []
        detailed_content = []
        
        for line in lines:
            if line.strip() == "** Brief Summary":
                in_brief = True
                in_medium = in_detailed = False
                continue
            elif line.strip() == "** Medium Summary":
                in_medium = True
                in_brief = in_detailed = False
                continue
            elif line.strip() == "** Detailed Summary":
                in_detailed = True
                in_brief = in_medium = False
                continue
            elif line.strip().startswith("** "):
                in_brief = in_medium = in_detailed = False
                continue
            
            if in_brief and line.strip():
                brief_content.append(line)
            elif in_medium and line.strip():
                medium_content.append(line)
            elif in_detailed and line.strip():
                detailed_content.append(line)
        
        # Print each summary level with formatting
        if brief_content:
            print("\nðŸ”¸ BRIEF SUMMARY:")
            print('-' * 40)
            for line in brief_content:
                print(line)
        
        if medium_content:
            print("\nðŸ”¸ MEDIUM SUMMARY:")
            print('-' * 40)
            for line in medium_content:
                print(line)
        
        if detailed_content:
            print("\nðŸ”¸ DETAILED SUMMARY:")
            print('-' * 40)
            for line in detailed_content:
                print(line)
        
        print("\n" + "="*80)
        
    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
        sys.exit(1)
    except Exception as e:
        print(f"Fatal error: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
